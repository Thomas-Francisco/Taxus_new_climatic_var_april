---
title: "GF_raw_outliers_detection_new_var"
author: "Thomas Francisco"
date: "2024-04-30"
output: html_document
---

This script will perform the outlier detection using gradient forest.

Gradient forest is a machine learning methods introduce by Ellis, Smith and Pitcher, 2012. Fitzpatrick & Keller (2015) described how GF can be used to (1) analyze and map spatial variation in allele frequencies as a function of environmental gradients and (outliers detection and GEA) (2) project patterns of genomic variation under future climate (genomic offset).
More precisely, "GF uses Random Forest to fit an ensemble of regression trees to model change in allele frequencies across sites and derive monotonic, nonlinear functions of environmental predictors. The empirical, nonlinear turnover functions are constructed by distributing the R^2 values from all SNPs among the predictor gradients in proportion to their accuracy importance and along each gradient according to the density of the raw split importance values. The split importance values for all modeled SNPs also are aggregated to an overall, genome-wide turnover function for each variable using weightings based on predictor importance and the goodness-of-fit for each SNP model" Fitzpatrick et al. (2021).
GF is a multivariate methods because it can handle multiple climatic variable at the same times but only one SNP per SNP.(RDA is also a multivariate methods because of that and also it can handle several response variables at the same time -> unique method that does that, LFMM can be univariate for both or same as GF, BAYPASS univariate).

In this script, we will use the GF algorithm for outlier detection following Fitzpatrick et al. (2021) and Archambeau et al. (2024).
We will perform the GF on a genomic dataset corrected and non-corrected for population structure (see script GF_corrected_outliers_detection)

To evaluate for each locus their association with climatic variables, we will compute empirical pvalues. These pvalues are calculated by comparing a nulle distribution of R2 with the R2 values of each locus and the more the R^2 values is away from the distribution, the more the pvalues is low.
To compute these pvalues, the first step is to select the SNP set that will be used to compute the null distribution.
If SNPs in intergenic regions or maybe SNPs in non coding regions identified by genetic load are available that is much better.
Unfortunately, here we do not have such SNPs, so I will use like Archambeau et al. 2024 a random subset of SNP from the dataset to create the null distribution.

There are 4 steps to perform the outlier detection with GF:  
    1. Formatting the genomic and the climatic data  
    2. Run GF  
    3. Calculating the empirical pvalues by comparing R^2 values of all SNP with the distribution of R^2 values of a random set of SNPs (if it can be neutral canditates from intergenic regions or maybe SNPs in non coding regions identified by genetic load? it would be better).  
    4. Selecting a threshold to identify canditates  
    5. Results of the 5 runs  
    
We will perform the last 3 steps 5 times for each dataset and select as canditates for each dataset the SNPs overlapping between the 5 runs because between runs the identified canditates could slightly change (Archambeau et al. 2024). 

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(cache = FALSE)
#download gradientforest package
#install.packages("gradientForest", repos=c("http://R-Forge.R-project.org",
#"http://cran.at.r-project.org"),dependencies=TRUE)
library(gradientForest)
library(dplyr)
library(tidyr)
library(writexl)
library(VennDiagram)
library(radiant.data) #for row_names_to_columns
library(textshape) #for colnames_to_row.names
```

This script will only perform the GF candidate identification non corrected for population structure (PS) (see script GF_corrected_outliers_detection for GF corrected for PS)

    1. Formatting the genomic and the climatic data

The format to perform the gradient forest (GF) according to Fitzpatrick et al. (2021) is to arrange populations in rows and single nucleotide polymorphisms (SNPs) in columns. It's important that the order of populations is consistent between the genomic data file and the climatic data file.

The genomic file is loaded with a minimum allele frequency (MAC) cutoff of 20, as low MAF alleles could potentially impact the genomic environmental association (GEA) (the same MAC threshold was applied for each GEA methods).

```{r formatting data}
#genomic data
load("C:/Users/tfrancisco/Documents/Thèse/Data/Espèces/Taxus_baccata/genetic_new/data_allelic_frequencies_29pop_adapcon_gentree_475_8616.Rdata")

genomic_matrix <- data_allelic_frequencies_29pop_adapcon_gentree_475_8616
#climatic data
Past_climatic <- read.csv("C:/Users/tfrancisco/Documents/Thèse/Data/Espèces/Taxus_baccata/Climatic_data/new_selection/Past_new_6_Climatic_data_scale_df.csv",sep=";",dec=",")
vars <- colnames(Past_climatic[,-c(1:2)])
```


Steps 2,3 are not showed in details here because we created a function do these steps but, they are explained in the script GF_outliers_detection_step_by_step.

    2/3. Results of the 5 runs
    
In this step, we will perform the GF 5 times because as explained above, the candidates can vary from one run to another due to the nature of the analysis (machine learning). (Moreover, the random null distribution could randomly select candidates so in order to take into account that, we will select for each runs the candidates identified by at least 2 of the 5 null distribution).

```{r function to perform the GF and output the results in 1 code, message=FALSE, warning=FALSE}


Run_GF_and_select_outliers <- function(genomic_matrix, climatic_data, ntree, cores,nbr_loci_distrib,vars,x,path){

  #GF function
  runGF <- function(alFreq,  envTab, vars, ntree, 
                  cores, indLoci){
  require(data.table)
  require(gradientForest)
  require(parallel)
  require(foreach)
  require(doParallel)
  library(doParallel)
  library(foreach)
  library(parallel)
  library(gradientForest)
  library(data.table)
  
  if(identical(envTab$Population,rownames(alFreq))==F){
    stop("Populations are not in the same order in the genomic and climatic tables.")
  }
  
  # create custom object to hold output 
  gfOutObj <- setClass("gfOutObj", slots = c(alFreq="data.frame", imp="list"))

  # run in parallel if fitting SNPs individually
  if(indLoci==T & !is.na(cores)){
    # fit gf model to each SNP individually
    cl <- makeCluster(cores, setup_strategy = "sequential")
    registerDoParallel(cl)

    gfMods <- foreach(k=1:ncol(alFreq), .verbose=F, .packages=c("gradientForest"), .errorhandling = c("pass")) %dopar%{
      locus <- data.frame(alFreq[,k])
      names(locus) <- colnames(alFreq)[k]
      gf.mod <- gradientForest(data.frame(envTab[, vars], locus), 
                               predictor.vars=vars, response.vars=colnames(alFreq)[k], 
                               corr.threshold=0.5, ntree=ntree, trace=T)
    if(!is.null(gf.mod)){
        imps <- importance(gf.mod)
        imps <- imps[order(names(imps))]
        data.frame(imps, SNP = colnames(alFreq)[k])
      }
    }
    
    stopCluster(cl)
    return(gfOutObj(alFreq = data.frame(alFreq), imp = gfMods))
  } else {
    # run all SNPs at once if not fitting individually
    gf.mod <- gradientForest(data.frame(envTab[, vars], alFreq), 
                             predictor.vars=vars, response.vars=colnames(alFreq), 
                             corr.threshold=0.5, ntree=ntree, trace=T)
    
    return(gfOutObj(alFreq = data.frame(alFreq), imp = gfMods))
  }
}
  #run GF
  GF_test <- runGF(genomic_matrix,climatic_data,vars,ntree=ntree, 
                  cores=cores, indLoci=T)
  
  #extract the loci correlated to the climate
  Extract_correlation_loci_climate<- GF_test@imp
loci_correlated_climate <- Filter(function(x) !inherits(x, "error"),  Extract_correlation_loci_climate)

#extracting R^2 values
gfR2tab <- function(gfMods.list){
  gfMods.list <- gfMods.list
  i=1
  while(is.null(gfMods.list[[i]])){i=i+1}
  tab <- do.call(rbind, gfMods.list)
  vrNm <- rep(row.names(tab)[1:nrow(gfMods.list[[i]])], 
              nrow(tab)/nrow(gfMods.list[[i]]))
  tab <- data.frame(variable=vrNm, tab)
  tab <- reshape2::dcast(tab, SNP~variable, value.var="imps")
  totalR2 <- rowSums(tab[,-1])
  return(data.frame(tab, totalR2=totalR2))}

dataset_R2_loci_climate <- gfR2tab(loci_correlated_climate)

  #select randomly the SNPs, we selected 20% of all SNPs to create the null distribution
name_neutral_snps <- sample(dataset_R2_loci_climate$SNP,nbr_loci_distrib,replace = F)

neutral_snps_set <- dataset_R2_loci_climate %>% 
    filter(SNP %in% name_neutral_snps)

#hist neutral 
 neutral_R2_distrib<-hist(neutral_snps_set$totalR2)
 
 #name
neutral_R2_distrib<-hist(neutral_snps_set$totalR2)


#save the histogram
 png(filename=paste0(path,x,"neutral_R2_distrib",".png"))

# a histogram we want to save
hist(neutral_snps_set$totalR2)

# call this function to save the file 
dev.off()
 
#empirical pvalues
empirical_pvalues <- sapply(1:nrow(dataset_R2_loci_climate), function(x, dataset_R2_loci_climate, name_neutral_snps, neutral_snps_set){
    snps2Rank <- rbind(dataset_R2_loci_climate[x,], neutral_snps_set) %>% 
      distinct() %>% 
      dplyr::select(-SNP)
    P <- apply(snps2Rank, 2, function(y){
      rankSNP <- frank(y)
      return(1-rankSNP[1]/length(rankSNP))
    })}, dataset_R2_loci_climate, neutral_snps, neutral_snps_set)
  

  # format output as data.frame
  empirical_pvalues_df <- t(empirical_pvalues)
  colnames(empirical_pvalues_df) <- paste("pval_", colnames(empirical_pvalues_df), sep="")
  empirical_pvalues_df <- data.frame(dataset_R2_loci_climate, empirical_pvalues_df)

    #visualise the pvalues distribution
  pvalues_distribution <- hist(empirical_pvalues_df$pval_totalR2)
  
  
  #save the histogram
png(filename=paste0(path,"pvalues_distribution",x,".png"))

# a histogram we want to save
hist(empirical_pvalues_df$pval_totalR2)

# call this function to save the file 
dev.off()
  # Return the pvalues 
  return(empirical_pvalues_df)

}

vars <- colnames(Past_climatic[,-c(1:2)])
path <- "C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/GF/raw/"

#for(x in 1:5){
#  name_file <- paste0("Run",x)
#  Run <- Run_GF_and_select_outliers(genomic_matrix, Past_climatic, 500, 4,600,vars,x=x,path)
#  applied(name_file, Run)
#}
```

We save the Runs of GF_raw if needed to rerun them to change threshold or perform new analysis/ figures

```{r save }
#for(x in 1:5){
#  save(paste0("Run",x),file=paste0("C:/Users/tfrancisco/Documents/Thèse/Data/Espèces/Taxus_baccata/GEA_new_var/GF_RAW/Run",x,".Rdata"))
#}
```

    4. Selecting a threshold to identify candidates 
We can load the run to skip the steps 1,2 and 3. 
```{r load RUNs}
for(x in 1:5){
  load(paste0("C:/Users/tfrancisco/Documents/Thèse/Data/Espèces/Taxus_baccata/GEA_new_var/GF_RAW/Run",x,".Rdata"))
}
```
    

Now we want to identified candidates To do that, we can calculate 2 types of thresholds:   
     **rank pvalues threshold:**  
        - rank based 5%  
        - rank based 1%  
        
     **pvalues threshold:**  
        - pvalues 0.05  
        - pvalues 0.01  
    
```{r calculation of thresholds}
for(i in 1:5){
  data_name <- paste0("Run",i)
  
  data <- get(data_name)
  
   #top 1%
 outliers_top1perc_GF <- data[,c(1,15)] %>% 
  arrange(pval_totalR2) %>%
slice(1:(0.01*8616)) %>%  #slice(1:(0.01*nrow(.)))
  as.data.frame()
 
 assign(paste0("Run",i,"_top1SNP"),outliers_top1perc_GF)
 
   #top 5%
 outliers_top5perc_GF <- data[,c(1,15)] %>% 
  arrange(pval_totalR2) %>%
slice(1:(0.05*nrow(data))) %>%  #slice(1:(0.01*nrow(.)))
  as.data.frame()
 
 assign(paste0("Run",i,"_top5SNP"),outliers_top5perc_GF)
 
 #pvalues < 0.05
outliers_pv05 <- data[,c(1,15)] %>% filter(pval_totalR2<0.05) %>% pull(SNP) 

 assign(paste0("Run",i,"_outliers_pv0.05"),outliers_pv05)

#pvalues < 0.01
outliers_pv0.01 <- data[,c(1,15)] %>% filter(pval_totalR2<0.01) %>% pull(SNP)
 
 assign(paste0("Run",i,"_outliers_pv0.01"),outliers_pv0.01)
}
```


One important step is to compare the results of the different runs for each threshold.
We realized venn_diagram plots to visualize the number of common candidates across runs

```{r venn_diagram representation for comparison across runs, message=FALSE, warning=FALSE}
  #outlier 0.01
venn.diagram(x = list(Run1_outliers_pv0.01, Run2_outliers_pv0.01, Run3_outliers_pv0.01, Run4_outliers_pv0.01, Run5_outliers_pv0.01),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = "C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/GF/raw/venn_diagramm_GF_raw_pv0.01.png",fill = c("#45B6AA", B = "#D45176", C = "#91A6CE", D = "#86AD4C","#33A5CE"),
alpha = 0.30,
print.mode=c("raw","percent"),
imagetype="png",
output=TRUE)


  #outliers 0.05
venn.diagram(x = list(Run1_outliers_pv0.05, Run2_outliers_pv0.05, Run3_outliers_pv0.05, Run4_outliers_pv0.05, Run5_outliers_pv0.05),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = "C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/GF/raw/venn_diagramm_GF_raw_pv0.05.png",fill = c("#45B6AA", B = "#D45176", C = "#91A6CE", D = "#86AD4C","#33A5CE"),
alpha = 0.30,
print.mode=c("raw","percent"),
imagetype="png",
output=TRUE
)


 #top 1%
venn.diagram(x = list(Run1_top1SNP[,1], Run2_top1SNP[,1], Run3_top1SNP[,1], Run4_top1SNP[,1], Run5_top1SNP[,1]),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = "C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/GF/raw/venn_diagramm_GF_raw_top1.png",fill = c("#45B6AA", B = "#D45176", C = "#91A6CE", D = "#86AD4C","#33A5CE"),
alpha = 0.30,
print.mode=c("raw","percent"),
imagetype="png",
output=TRUE
)

 #top 5%
s=venn.diagram(x = list(Run1_top5SNP[,1], Run2_top5SNP[,1], Run3_top5SNP[,1],Run4_top5SNP[,1], Run5_top5SNP[,1]),
        category.names = c("RUN1" , "RUN2 ","RUN3","RUN4","RUN5"),
        filename = "C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/GF/raw/venn_diagramm_GF_raw_top5.png",fill = c("#45B6AA", B = "#D45176", C = "#91A6CE", D = "#86AD4C","#33A5CE"),
alpha = 0.30,
print.mode=c("raw","percent"),
imagetype="png",
output=TRUE
)
```

Globally, we can see that only a part of all the snps identified as candidates are common across runs. That is a result that inform us that using GF as candidates detection methods is maybe not the best method. 
As candidates, we selected and save the top :

        - 1% of SNPs for downstream analysis
```{r select the overlapping candidates across runs and save them 1%}
#Select only the candidates identified in all 5 runs
outliers_rank_based_top1perc_GF_raw <- Reduce(intersect, list(Run1_top1SNP[,1],Run2_top1SNP[,1],Run3_top1SNP[,1],Run4_top1SNP[,1], Run5_top1SNP[,1]))

#save
save(outliers_rank_based_top1perc_GF_raw,file="C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/outliers/outliers_rank_based_top1perc_GF_raw.Rdata", force=T)
```

      - 5% of SNPs for downstream analysis as a relax threshold candidates
      
```{r select the overlapping candidates across runs and save them 5%}
#Select only the outliers identified in all 5 runs
outliers_rank_based_top5perc_GF_raw <- Reduce(intersect, list(Run1_top5SNP[,1],Run2_top5SNP[,1],Run3_top5SNP[,1],Run4_top5SNP[,1], Run5_top5SNP[,1]))

#save
save(outliers_rank_based_top5perc_GF_raw,file="C:/Users/tfrancisco/Documents/Thèse/Results/species/taxus/GEA_new_var/outliers/outliers_rank_based_top5perc_GF_raw.Rdata", force=T)
```